<!doctype html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>LEAD-ME Summer Training School Warsaw 2021 Programme</title><meta name="description" content="Programme of LEAD-ME Summer School 2021."><script src="/js/menubar/MenubarLinks.js" type="text/javascript"></script><script src="/js/menubar/MenubarItemLinks.js" type="text/javascript"></script><script src="/js/menubar/PopupMenuLinks.js" type="text/javascript"></script><script src="/js/menubar/PopupMenuItemLinks.js" type="text/javascript"></script><script src="/js/menubutton/MenuItemLinks.js" type="text/javascript"></script><script src="/js/menubutton/Menubutton2.js" type="text/javascript"></script><script src="/js/menubutton/PopupMenuLinks.js" type="text/javascript"></script><link rel="stylesheet" href="/css/main.css"></head><body><header><a class="skip-link" href="#main">Skip to main content</a><div class="headerContainer"><div class="headerBig"><a href="/"><img src="/images/leadme-logo-white.svg" alt="LEAD-ME logo"></a></div><div class="headerLarge"><a href="/">Leading Platform for European Citizens, Industries, Academia and Policymakers in Media Accessibility</a></div></div><nav class="mainNav"><div class="mainNavContainer"><ul role="menubar" id="mainNavMenu"><li role="none"><a role="menuitem" aria-haspopup="true" aria-expanded="false" tabindex="0">The Action</a><ul role="menu" aria-label="The Action"><li role="none"><a role="menuitem" tabindex="0" href="/action/programme/">About</a></li><li role="none"><a role="menuitem" tabindex="0" href="/action/objectives/">Objectives</a></li><li role="none"><a role="menuitem" tabindex="0" href="/action/members/">Members</a></li><li role="none"><a role="menuitem" tabindex="0" href="/action/working-groups/">Working Groups</a></li><li role="none"><a role="menuitem" tabindex="0" href="/action/deliverables/">Deliverables</a></li></ul></li><li role="none"><a role="menuitem" aria-haspopup="true" aria-expanded="false" tabindex="0">Grants</a><ul role="menu" aria-label="Grants"><li role="none"><a role="menuitem" tabindex="0" href="/grants/types/">Type of Grant</a></li><li role="none"><a role="menuitem" tabindex="0" href="/grants/grantees/">Grantees</a></li><li role="none"><a role="menuitem" tabindex="0" href="/grants/apply/">How to apply</a></li><li role="none"><a role="menuitem" tabindex="0" href="/grants/calls/">Open Calls</a></li></ul></li><li role="none"><a role="menuitem" aria-haspopup="true" aria-expanded="false" tabindex="0">News & Events</a><ul role="menu" aria-label="News & Events"><li role="none"><a role="menuitem" tabindex="0" href="/events/leadme-events/">LEAD-ME Events</a></li><li role="none"><a role="menuitem" tabindex="0" href="/events/leadme-related/">Related Events</a></li><li role="none"><a role="menuitem" tabindex="0" href="/mediaroom/news/">Press</a></li><li role="none"><a role="menuitem" tabindex="0" href="/events/lead-me-news/">LEAD-ME News</a></li><li role="none"><a role="menuitem" tabindex="0" href="/events/trainingschools/">Training Schools</a></li><li role="none"><a role="menuitem" tabindex="0" href="/events/newsletters/">Newsletters</a></li></ul></li><li role="none"><a role="menuitem" aria-haspopup="true" aria-expanded="false" tabindex="0">Resources</a><ul role="menu" aria-label="Resources"><li role="none"><a role="menuitem" tabindex="0" href="/mediaroom/publications/">Publications</a></li><li role="none"><a role="menuitem" tabindex="0" href="/mediaroom/collaborators/">Collaborators</a></li><li role="none"><a role="menuitem" tabindex="0" href="/mediaroom/videos/">Videos</a></li><li role="none"><a role="menuitem" tabindex="0" href="/mediaroom/resources/">Assets</a></li></ul></li><li role="none"><a role="menuitem" aria-haspopup="true" aria-expanded="false" tabindex="0">Contact</a><ul role="menu" aria-label="Contact"><li role="none"><a role="menuitem" tabindex="0" href="/contact/contactinfo/">Contact info</a></li><li role="none"><a role="menuitem" tabindex="0" href="/contact/participate/">Participate</a></li></ul></li></ul></div><div class="smallNavContainer menu_button"><button type="button" aria-label="menu" class="hamIcon" id="menubutton" aria-haspopup="true" aria-controls="menu2"><svg viewBox="0 0 80 80" width="30" height="30"><rect width="100" height="12"></rect><rect y="30" width="100" height="12"></rect><rect y="60" width="100" height="12"></rect></svg></button><ul role="menu" id="menu2" aria-labelledby="menubutton"><li role="none"><a role="none">The Action</a></li><li role="none"><a role="menuitem" href="/action/programme/">About</a></li><li role="none"><a role="menuitem" href="/action/objectives/">Objectives</a></li><li role="none"><a role="menuitem" href="/action/members/">Members</a></li><li role="none"><a role="menuitem" href="/action/working-groups/">Working Groups</a></li><li role="none"><a role="menuitem" href="/action/deliverables/">Deliverables</a></li><li role="none"><a role="none">Grants</a></li><li role="none"><a role="menuitem" href="/grants/types/">Type of Grant</a></li><li role="none"><a role="menuitem" href="/grants/grantees/">Grantees</a></li><li role="none"><a role="menuitem" href="/grants/apply/">How to apply</a></li><li role="none"><a role="menuitem" href="/grants/calls/">Open Calls</a></li><li role="none"><a role="none">News & Events</a></li><li role="none"><a role="menuitem" href="/events/leadme-events/">LEAD-ME Events</a></li><li role="none"><a role="menuitem" href="/events/leadme-related/">Related Events</a></li><li role="none"><a role="menuitem" href="/mediaroom/news/">Press</a></li><li role="none"><a role="menuitem" href="/events/lead-me-news/">LEAD-ME News</a></li><li role="none"><a role="menuitem" href="/events/trainingschools/">Training Schools</a></li><li role="none"><a role="menuitem" href="/events/newsletters/">Newsletters</a></li><li role="none"><a role="none">Resources</a></li><li role="none"><a role="menuitem" href="/mediaroom/publications/">Publications</a></li><li role="none"><a role="menuitem" href="/mediaroom/collaborators/">Collaborators</a></li><li role="none"><a role="menuitem" href="/mediaroom/videos/">Videos</a></li><li role="none"><a role="menuitem" href="/mediaroom/resources/">Assets</a></li><li role="none"><a role="none">Contact</a></li><li role="none"><a role="menuitem" href="/contact/contactinfo/">Contact info</a></li><li role="none"><a role="menuitem" href="/contact/participate/">Participate</a></li></ul></div></nav></header><main id="main"><div class="mainContainer"><h1 id="mainHeading">LEAD-ME Summer Training School Warsaw 2021 Programme</h1><h2>Eye tracking in media accessibility research - methods, technologies and data analyses</h2><p class="padbot32"><strong>5-9 July 2021 - Online</strong></p><ul><li><a href="/events/ss2021programme/#monday">Day1: Monday 5th July</a></li><li><a href="/events/ss2021programme/#tuesday">Day2: Tuesday 6th July</a></li><li><a href="/events/ss2021programme/#wednesday">Day3: Wednesday 7th July</a></li><li><a href="/events/ss2021programme/#thursday">Day4: Thursday 8th July</a></li><li><a href="/events/ss2021programme/#friday">Day5: Friday 9th July</a></li><li><a href="/events/ss2021programme/#tutors">Tutors for Students' Projects</a></li><li><a href="/events/ss2021programme/#bios">Speaker Bios</a></li><li><a href="/events/ss2021programme/#abstracts">Abstracts</a></li></ul><h3 id="monday" class="padtop32 padbot32 before_tab_schedule">Monday 5th July</h3><table><thead><tr><th>Time (CET)</th><th></th></tr></thead><tbody><tr><td>09:00 - 10:00</td><td><strong>Keynote</strong> - <a href="#paivi">Paivi Majaranta</a>, <a href="#abs1">Vision for Augmented Humans</a></td></tr><tr><td>10:00 - 10:15</td><td>Coffee Break</td></tr><tr><td>10:15 - 12:30</td><td><strong>Lecture</strong> - <a href="#izabela">Izabela Krejtz</a>, <a href="#abs9">Experimental Designs in Eye Tracking Studies</a></td></tr><tr><td>12:30 - 13:30</td><td>Lunch Break</td></tr><tr><td>13:30 - 15:45</td><td><strong>Workshop</strong> - <a href="#adam">Adam Cellary</a>, <a href="#abs10">Webcam-base Eye Tracking</a></td></tr><tr><td>15:45 - 16:00</td><td>Coffee Break</td></tr><tr><td>16:00 - 18:00</td><td><strong>Hands-on Session</strong> - Ideas Creation, Pitch Session, Research questions &amp; Hypotheses</td></tr></tbody></table><h3 id="tuesday" class="padtop32 padbot32 before_tab_schedule">Tuesday 6th July</h3><table><thead><tr><th>Time (CET)</th><th></th></tr></thead><tbody><tr><td>09:00 - 10:00</td><td><strong>Lecture</strong> - <a href="#miroslav">Miroslav Vujičić</a> and <a href="#ugljesa">Uglješa Stankov</a>, <a href="#abs6">Tourism Accessibility 4.0 - A Transition of e-Accessibility in Tourism Towards a More Inclusive Future</a></td></tr><tr><td>10:00 - 10:15</td><td>Coffee Break</td></tr><tr><td>10:15 - 12:30</td><td><strong>Workshop</strong> - <a href="#kryz">Krzysztof Krejtz</a>, <a href="#abs11">Statistical Analysis of Eye Tracking Data</a></td></tr><tr><td>12:30 - 13:30</td><td>Lunch Break</td></tr><tr><td>13:30 - 15:45</td><td><strong>Workshop</strong> - <a href="#andrew">Andrew T. Duchowski</a>, <a href="#abs4">Eye Tracking Data Analytic Pipeline</a></td></tr><tr><td>15:45 - 16:00</td><td>Coffee Break</td></tr><tr><td>16:00 - 18:00</td><td><strong>Hands-on Session</strong> - Method Design, Procedure Design, Stimuli Collection</td></tr></tbody></table><h3 id="wednesday" class="padtop32 padbot32 before_tab_schedule">Wednesday 7th July</h3><table><thead><tr><th>Time (CET)</th><th></th></tr></thead><tbody><tr><td>09:00 - 10:00</td><td><strong>Keynote</strong> - <a href="#kruger">Jan-Louis Kruger</a>, <a href="#abs2">Audiovisual Translation as multimodal mediation</a></td></tr><tr><td>10:00 - 10:15</td><td>Coffee Break</td></tr><tr><td>10:15 - 12:30</td><td><strong>Lecture</strong> - <a href="#breno">Breno Silva</a> &amp; <a href="#agnieszka">Agnieszka Szarkowska</a>, <a href="#abs5">Using Linear Mixed Models to Analyse Subtitle Reading</a></td></tr><tr><td>12:30 - 13:30</td><td>Lunch Break</td></tr><tr><td>13:30 - 15:45</td><td><strong>Hands-on Session</strong> - Experimental Procedure Implementation</td></tr><tr><td>15:45 - 16:00</td><td>Coffee Break</td></tr><tr><td>16:00 - 18:00</td><td><strong>Workshop</strong> - <a href="#craig">Craig Hennessey</a>, <a href="#abs13">Introduction to Eye-Tracking Equipment: Setup, Recording, and Analysis</a></td></tr></tbody></table><h3 id="thursday" class="padtop32 padbot32 before_tab_schedule">Thursday 8th July</h3><table><thead><tr><th>Time (CET)</th><th></th></tr></thead><tbody><tr><td>09:00 - 10:00</td><td><strong>Keynote</strong> - <a href="#pilar">Pilar Orero</a> , <a href="#abs3">Future of Media Accessibility and Research</a></td></tr><tr><td>10:00 - 10:15</td><td>Coffee Break</td></tr><tr><td>10:15 - 12:30</td><td><strong>Lecture</strong> - <a href="#anna">Anna Matamala</a>, <a href="#abs7">Qualitative Research Methods in Media Accessibility: Focus Groups and Interviews</a></td></tr><tr><td>12:30 - 13:30</td><td>Lunch Break</td></tr><tr><td>13:30 - 14:45</td><td><strong>Workshop</strong> - <a href="#karolina">Karolina Broś</a>, <a href="#abs12">Literature review - reading and writing eye-tracking research papers</a></td></tr><tr><td>14:45 - 15:45</td><td><strong>Lecture</strong> - <a href="#jankowska">Anna Jankowska</a>, <a href="#abs8">Using Translation Process Methods in Audiovisual Translation and Media Accessibility Research</a></td></tr><tr><td>15:45 - 16:00</td><td>Coffee Break</td></tr><tr><td>16:00 - 18:00</td><td><strong>Hands-on Session</strong> - Data Collection &amp; Analysis</td></tr></tbody></table><h3 id="friday" class="padtop32 padbot32 before_tab_schedule">Friday 9th July</h3><table><thead><tr><th>Time (CET)</th><th></th></tr></thead><tbody><tr><td>09:00 - 11:15</td><td><strong>Hands-on Session</strong> - Students' Projects Presentations</td></tr><tr><td>11:15 - 11:30</td><td>Coffee Break</td></tr><tr><td>11:30 - 12:30</td><td><strong>Lecture</strong> - <a href="#chris">Chris Hughes</a>, Eye Tracking Research in Virtual Reality</td></tr><tr><td>12:30 - 13:45</td><td><strong>Farewell &amp; Winter School announcement</strong> - Pilar Orero, Agnieszka Szarkowska, Krzysztof Krejtz, Juanpe Rica</td></tr></tbody></table><h3 id="tutors" class="padtop32">Tutors for Students' Projects</h3><ol><li>Agnieszka Szarkowska (University of Warsaw, Poland)</li><li>Izabela Krejtz (SWPS University of Social Sciences and Humanities, Poland)</li><li>Andrew T. Duchowski (Clemson University, SC, USA)</li><li>Alina Secara (University of Vienna, Austria)</li><li>Breno Silva (University of Warsaw)</li><li>Karolina Broś (University of Warsaw)</li><li>Katarzyna Wisiecka (SWPS University of Social Sciences and Humanities, Poland)</li><li>Beata Lewandowska (RealEye, Poland)</li><li>Krzysztof Krejtz (SWPS University of Social Sciences and Humanities, Poland)</li></ol><h3 id="bios" class="padtop32">Speaker Bios</h3><h4 id="paivi">Päivi Majaranta (Tampere University, Finland)</h4><p class="biophoto"><img src="/images/ss21_Paivi_Majaranta.jpg" alt=""></p><p>Päivi Majaranta is a Senior Research Fellow at Tampere University, Finland, where she teaches courses on human-technology interaction. Her research interests include gaze interaction, multimodal interfaces, user experience, animal-computer interaction. She holds MSc in Computer Science (1998) and PhD in Interactive Technology (2009) from the University of Tampere. She is the former president and current member of the management board of the COGAIN Association, a member of the ACM ETRA Steering Committee, and a member of the editorial board of the Journal of Eye Movement Research. She has over 60 peer-reviewed publications in the field of human-computer interaction.</p><h4 id="kruger" class="padtop32 clearleft">Jan-Louis Kruger (Macquarie University, Australia)</h4><p class="biophoto"><img src="/images/ss21_Jan_Louis-Kruger.jpg" alt=""></p><p>Jan-Louis Kruger is professor and Head of the Department of Linguistics at Macquarie University. He started his research career in English literature with a particular interest in the way in which Modernist poets and novelists manipulate language, and in the construction of narrative point of view. From there he started exploring the creation of narrative in film and how audiovisual translation (subtitling and audio description) facilitates the immersion of audiences in the fictional reality of film.</p><p>In the past decade his attention has shifted to the multimodal integration of language in video where auditory and visual sources of information supplement and compete with text in the processing of subtitles. His research uses eye tracking experiments (combined with psychometric instruments and performance measures) to investigate the cognitive processing of language in multimodal contexts. His current work looks at the impact of redundant and competing sources of information on the reading of subtitles at different presentation rates and in the presence of different languages.</p><h4 id="pilar" class="padtop32 clearleft">Pilar Orero (Universidad Autónoma de Barcelona, Spain)</h4><p class="biophoto"><img src="/images/ss21_Pilar_Orero.jpeg" alt=""></p><p>Pilar Orero is the INDRA-ADDECCO Chair in Accessible Technology and full professor of Audiovisual Translation at the Universitat Autònoma de Barcelona (Spain), where she leads the TransMedia Catalonia Research Group. She acts as Gian Maria Greco's Supervisor in the MSCA H2020 project &quot;Understanding Media Accessibility Quality&quot; (UMAQ).</p><p>She is a world-leading scholar in media accessibility with vast experience in standardisation and policy-making, She is a scientific/organizing committee member of many conferences, including Media4All, ARSAD, and Video Games for All. She has delivered, upon invitation, more than 15 plenary lectures and 30 guest lectures all over the world, including at the 9th United Nations Conference of the States Parties to the Convention on the Rights of Persons with Disabilities (New York, 2016).</p><p>She either coordinated or participated in more than 40 national and international research projects, of which more than 20 were on media accessibility. She has published over 70 papers and 10 books. Her works are some of the most widely-cited publications in the field of media accessibility, of which she is one of the founding scholars.</p><h4 id="izabela" class="padtop32 clearleft">Izabela Krejtz (SWPS University of Social Sciences and Humanities, Poland)</h4><p class="biophoto"><img src="/images/ss21_Iza_krejtz.jpeg" alt=""></p><p>Izabela Krejtz is an associate professor of psychology at SWPS University of Social Sciences and Humanities, Warsaw, Poland. She is a recognized researcher in the field of cognitive psychopathology, educational psychology, and daily experience measured with the momentary ecological assessment. She is an author of several dozens of international scientific publications among which a large amount was based on eye tracking experiments. She regularly teaches experimental research methodology and eye tracking method applications in media research.</p><h4 id="adam" class="padtop32 clearleft">Adam Cellary (RealEye, Poland)</h4><p class="biophoto"><img src="/images/ss21_Adam_Cellary.jpg" alt=""></p><p>Adam Cellary, graduated from Warsaw University of Technology, Robotics on Mechatronics. Interested in eye-tracking from the technical point of view since 2012. Entrepreneur and Developer by heart.</p><h4 id="andrew" class="padtop32 clearleft">Andrew T. Duchowski (Clemson University, SC, USA)</h4><p class="biophoto"><img src="/images/ss21_Andrew_Duchowsk.png" alt=""></p><p>Andrew T. Duchowski is a professor of Computer Science at Clemson University. He received his baccalaureate (1990) from Simon Fraser University, Burnaby, Canada, and doctorate (1997) from Texas A&amp;M University, College Station, TX, both in Computer Science. His research and teaching interests include visual attention and perception, eye tracking, computer vision, and computer graphics. He is a noted research leader in the field of eye tracking, having produced a corpus of papers and a monograph related to eye tracking research, and has delivered courses and seminars on the subject at international conferences. He maintains Clemson's eye tracking laboratory, and teaches a regular course on eye tracking methodology attracting students from a variety of disciplines across campus.</p><h4 id="kryz" class="padtop32 clearleft">Krzysztof Krejtz (SWPS University of Social Sciences and Humanities, Poland)</h4><p class="biophoto"><img src="/images/ss21_Krzysztof-Krejtz.jpg" alt=""></p><p>Krzysztof Krejtz, Ph.D., is psychologist at SWPS University of Social Sciences and Humanities in Warsaw, Poland, where he is leading the Eye Tracking Research Center. In 2017 he was a guest professor at Ulm University, in Ulm, Germany. He gave several invited talks at e.g., Max-Planck Institute (Germany), Bergen University (Norway), Lincoln University Nebraska (USA). He has extensive experience in social and cognitive psychology research methods and statistics. In his research he focuses on the use of eye tracking method and developing novel metrics which may capture the dynamics of attention and information processing processes (transitions matrices entropy, ambient-focal coefficient K), dynamics of attention process in the context of Human Computer Interaction, multimedia learning, media user experience, and accessibility. He is a member of ACM Symposium on Eye Tracking Research and Application (ACM ETRA) Steering Committee and he was a general chair of ACM ETRA 2018 and 2019.</p><h4 id="breno" class="padtop32 clearleft">Breno Silva (University of Warsaw, Poland)</h4><p class="biophoto"><img src="/images/ss21_BrenoSilva.jpeg" alt=""></p><p>Breno Silva holds two MAs in Education (Universities of Warsaw and Nottingham) and a PhD in Applied Linguistics (University of Warsaw). He is a teacher and researcher. As a teacher, Breno holds workshops on the basics of statistics and on research methodology in applied linguistics. As a researcher, his main interests include lexical learning through reading and writing. Currently, Breno is involved in applied linguistics and psycholinguistics research, both concerning the learning of second and third language vocabulary.</p><h4 id="agnieszka" class="padtop32 clearleft">Agnieszka Szarkowska (University of Warsaw, Poland)</h4><p class="biophoto"><img src="/images/ss21_AgnieszkaSzarkowska.jpg" alt=""></p><p>Agnieszka Szarkowska is University Professor in the Institute of Applied Linguistics, University of Warsaw, and Head of the AVT Lab research group. She is a researcher, academic teacher, ex-translator, and translator trainer. Her research projects include eye tracking studies on subtitling, audio description, multilingualism in subtitling for the deaf and the hard of hearing, and respeaking. She now leads an international research team working on the project “Watching Viewers Watch Subtitled Videos”. Agnieszka is also the Vice-President of the European Association for Studies in Screen Translation (ESIST), a member of European Society for Translation Studies (EST) and an honorary member of the Polish Audiovisual Translators Association (STAW).</p><h4 id="miroslav" class="padtop32 clearleft">Miroslav Vujičić (University of Novi Sad, Serbia)</h4><p class="biophoto"><img src="/images/ss21_Miroslav.jpg" alt=""></p><p>Miroslav Vujičić is associate professor at the University of Novi Sad, Faculty of Sciences. Main field of interest is decision making processes, project management, product development, cultural tourism and has proficiency in data gathering, analysis and interpretation of mathematical and statistical methods. He has published 26 research papers at Scopus indexed journals and has more than 274 citations in the Scopus database. Programme Leader, BA Hons tourism. RVP for Eastern Europe in the ITSA network. Department coordinator for international affairs and students and staff mobility. He is the main evaluator for impact assessment of European Capital of Culture Novi Sad 2022. He is an experienced project manager and researcher with several international projects (EXtremeCLimTwin, CULTURWB, DiCultYouth, euCULTher, WATERTOUR).</p><h4 id="ugljesa" class="padtop32 clearleft">Uglješa Stankov (University of Novi Sad, Serbia)</h4><p class="biophoto"><img src="/images/ss21_Ugljesa%20Stankov%202021%20.jpg" alt=""></p><p>Uglješa Stankov is an Associate Professor at the Department of Geography, Tourism and Hotel Management, Faculty of Sciences, University of Novi Sad. His main research areas are the strategic role of information technology in tourism experiences and location intelligence in business activities. Due to the growing negative impact that inadequate use of information technology has on the digital well-being of consumers, the focus of his recent research is on the &quot;calm&quot; design of interactive systems in tourism and hospitality, as well as on technology-assisted mindfulness (e-mindfulness). Uglješa actively cooperates with researchers and professional organizations from the country and the world and currently participates in several international projects. He has published more than 150 scientific papers and four books.</p><h4 id="anna" class="padtop32 clearleft">Anna Matamala (Universidad Autónoma de Barcelona, Spain)</h4><p class="biophoto"><img src="/images/ss21_Anna_Matamala.jpeg" alt=""></p><p>Anna Matamala, BA in Translation (UAB) and PhD in Applied Linguistics (UPF), is an associate professor at Universitat Autònoma de Barcelona. Currently leading TransMedia Catalonia, she has participated and led projects on audiovisual translation and media accessibility. She has taken an active role in the organisation of scientific events (M4ALL, ARSAD), and has published in journals such as Meta, Translator, Perspectives, Babel, Translation Studies. She is currently involved in standardisation work.</p><h4 id="jankowska" class="padtop32 clearleft">Anna Jankowska (University of Antwerp, Belgium)</h4><p class="biophoto"><img src="/images/ss21_Anna_Jankowska.jpg" alt=""></p><p>Anna Jankowska, PhD, is a Professor at the Department of Translators and Interpreters of University of Antwerp and former Assistant Lecturer in the Chair for Translation Studies and Intercultural Communication at the Jagiellonian University in Krakow (Poland). She was a visiting scholar at the Universitat Autònoma de Barcelona within the Mobility Plus program of the Polish Ministry of Science and Higher Education (2016-2019). Her recent research projects include studies on audio description process, mobile accessibility and software.</p><h4 id="chris" class="padtop32 clearleft">Christopher Hughes (Salford University, UK)</h4><p class="biophoto"><img src="/images/avatar.jpg" alt=""></p><p>Dr Chris Hughes is a Lecturer in the School of Computer Science at Salford University, UK. His research is focused heavily on developing computer science solutions to promote inclusivity and diversity throughout the broadcast industry. This aims to ensure that broadcast experiences are inclusive across different languages, addressing the needs of those with hearing and low vision problems, learning difficulties and the aged. He was a partner in the H2020 Immersive Accessibility (ImAc) Project.</p><h4 id="karolina" class="padtop32 clearleft">Karolina Broś (University of Warsaw, Poland)</h4><p class="biophoto"><img src="/images/ss21_Karolina_Bros.jpg" alt=""></p><p>Karolina Broś, PhD is an assistant professor at the Institute of Applied Linguistics, University of Warsaw. She specialises in theoretical and experimental approaches to language research. Her recent projects include behavioural perception studies and EEG experiments focused on language processing in Spanish and other languages. She is currently running a project funded by the National Science Center on the acoustic, auditory and gestural correlates of consonantal contrasts in Spanish. She has published in several of the best journals in the field of linguistics, such as Journal of Linguistics, Phonetica, Journal of Neurolinguistics or Phonology. At the Institute of Applied Linguistics, she is actively engaged as an M.A. supervisor and tutor, and gives seminars on experimental approaches to linguistic research, translation and interpreting, as well as bilingualism and the brain.</p><h4 id="craig" class="padtop32 clearleft">Craig Hennessey (University of British Columbia, British Columbia Institute of Technology, and Gazepoint)</h4><p class="biophoto"><img src="/images/ss21_Craig_Hennessey.png" alt=""></p><p>Dr. Craig Hennessey PhD P.Eng, completed his doctorate at the University of British Columbia in 2008. Dr. Hennessey’s Master’s thesis involved the creation of a single camera based eye-tracker, while his doctoral work was on extending eye-tracking from 2D screens to 3D volumetric displays. After graduation he cofounded the eye-tracking company Gazepoint where he continues to develop innovative solutions in the field of eye-tracking.</p><h3 id="abstracts" class="padtop32 clearleft">Abstracts</h3><h4 id="abs1">Vision for Augmented Humans</h4><p>Eyeglasses once revolutionized human vision by offering an easy, non-invasive way to compensate for deficiencies in vision. Similarly, multimodal wearable technology may act as a facilitator to non-invasively augment human senses, action, and cognition - seamlessly, as if the enhancements were part of our natural abilities. In many scenarios, gaze plays a crucial role due to its unique capability to convey the focus of interest. Gaze has already been used in assistive technologies to compensate for impaired abilities. There are lessons learned that can be applied in human augmentation. In this talk, I will summarize some key lessons learned from the research conducted over the past decades. I will also discuss the role of gaze in multimodal interfaces and examine how different types of eye movements, together with other modalities, such as haptics, can support this intention. I will end with a call for research to realize the vision for an augmented human.</p><h4 id="abs2" class="padtop32">Audiovisual Translation as multimodal mediation</h4><p>The world of audiovisual media has changed on a scale last seen with the shift away from print to digital photography. VOD has moved from an expensive concept limited by technology and bandwidth, to the norm in most of not only the developed world, but also as an accelerated equaliser in developing countries. This has increased the reach and potential of audiovisual translation to facilitate intercultural communication, although automated means of creating subtitles poses some threats.</p><p>While the skills required to create AVT have come within reach of a large groups of practitioners due to advances in editing software and technology, with many processes from transcription to cuing being automated, research on the reception and processing of multimodal texts has also developed rapidly. This has given us new insights into the way viewers, for example, process the text of subtitles while also attending to auditory input as well as the rich visual code of film. This multimodality of film, although being acknowledged as one of the unique qualities of translation in this context, is also often overlooked in technological advances. When the emphasis is on the cheapest and simplest way of transferring spoken dialogue to written text, or visual scenes to auditory descriptions, the complex interplay between language and other signs is often overlooked.</p><p>Eye tracking provides a powerful tool for investigating the cognitive processing of viewers when watching subtitled film with research in this area drawing on cognitive science, psycholinguistics and psychology. I will present a brief description of eye tracking in AVT as well as the findings of some recent studies on subtitle reading at different subtitle presentation rates as well as in the presence of secondary visual tasks.</p><h4 id="abs3" class="padtop32">The Future of Media Accessibility and its Research: Leaving No One Behind</h4><p>With the risk of sounding &quot;Mystic Meg&quot; the presentation will look at some facts that will impact research topics on Media Accessibility. The EU legislative and political frameworks will be the transposition across Europe of the EU Media Accessibility Directive (AVMSD) and the European Accessibility Act (EAA). The need for objective research based data towards drafting accessibility service national standards will be next. The new legislation requests both quantity and quality of access services, hence national standards for benchmarking, regulating and reporting will be a matter of urgency. Media accessibility will be fully mainstreamed as any industrial service where the pull is legislation like Health and Safety. The growing number of accessibility services will offer plenty of scope in terms of training and research. Intelligent technology will allow for both personalisation of services, and the development of the Common User Profile, not losing sight on data desegregation and fairness issues. Leaving the clinical disability model of accessibility user classification for a capabilities framework should lead to revising some results and start new studies. The immersive media formats should offer enough research questions for all, from all methodological approaches. Internet of Things will also have an impact in the production, distribution, and reception of media access services: New working practices, applying blockchain to access services copyright, and the explosion of sound as a media object will keep us busy in the next coming years. The expansion of media accessibility services -beyond broadcast and movies- into other industrial sectors such as Education,Tourism, and Risk Reduction Management. And finally all the research and training should follow the UN Sustainable Development Cooperation Framework, where the first principle is to work within a Human Rights context and the second is &quot;Living No One Behind&quot;.</p><h4 id="abs9" class="padtop32">Experimental Designs in Eye Tracking Studies</h4><p>The lecture will recap the most important issues of experimental eye tracking study methodology including experimental designs within-subjects, between-subjects and mixed-designs and hypotheses testing. The lecture will introduce key concepts of eye tracking methodology: short review of available types of eye trackers, their pros and cons in the context of different usages, key information which can be obtained with the eye movements tracking. I will also introduce the most commonly used metrics used in eye tracking research.</p><h4 id="abs10" class="padtop32">Webcam-based Eye Tracking Method</h4><p>The workshop will cover the most important aspects of webcam eye tracking methodology.</p><ul><li>What is webcam eye tracking?</li><li>What are the key differences when using glasses, screen-mounted or webcam as input?</li><li>How to gather ET data, what to expect when hiring a panel?</li><li>What results expect from ET sessions (gaze-based data vs. fixation based data)?</li><li>Diving into results (heatmaps, recordings, fixation plots)</li></ul><p>The workshop will end with Q&amp;A Session</p><h4 id="abs4" class="padtop32">Eye Tracking Data Analytic Pipeline</h4><p>This tutorial gives a short introduction to experimental design in general and with regard to eye tracking studies in particular. Additionally, the design of three different eye tracking studies (using stationary as well as mobile eye trackers) will be presented and the strengths and limitations of their designs will be discussed. Further, the tutorial presents details of a Python-based gaze analytics pipeline developed and used by Drs. Duchowski and Gehrer. The gaze analytics pipeline consists of Python scripts for extraction of raw eye movement data, analysis and event detection via velocity-based filtering, collation of events for statistical evaluation, analysis and visualization of results using R. Attendees of the tutorial will have the opportunity to run the scripts of an analysis of gaze data collected during categorization of different emotional expressions while viewing faces. The tutorial covers basic eye movement analytics, e.g., fixation count and dwell time within AOIs, as well as advanced analysis using gaze transition entropy. Newer analytical tools and techniques such as microsaccade detection and the Index of Pupillary Activity will be covered with time permitting.</p><h4 id="abs11" class="padtop32">Statistical Analysis of Eye Tracking Data</h4><p>The course will focus on analysis of data from eye tracking experiments in R a computational language for statistics. We will cover topics from data frames management and formatting, analysis of visual attention distribution (analysis based on Area of Interests), to dynamics of visual attention process (e.g., discerning ambient - focal attention). Fundamental eye tracking metrics will be analysed with parametric statistical tests, eg. t-tests or ANOVA (of within- between- and mixed- designs) and linear regression (with moderation and mediation analysis). Participants of the course will receive ready to use R scripts with the most common statistical analysis of eye tracking data in R as well as scripts for preparing publication-ready visualizations of statistically significant effects. Note that no prior knowledge of programming in R is required for this workshop.</p><h4 id="abs5" class="padtop32">Using Linear Mixed Models to Analyse Subtitle Reading</h4><p>Using eye-tracking methods to research the reading of subtitles by viewers often warrant controlling for many confounding variables. However, it may be impossible to control for all these variables, even assuming that they are known to researchers. More traditional statistical methods such as t-tests exacerbate the problem. The issue is that, to run such statistical analyses, the data need to be aggregated so that each participant has one data point per dependent variable. In doing so, variance within the data is lost: for example, different subtitle characteristics may affect results differently, and t-tests cannot account for this. One solution is to use linear mixed models (LMMs). In this workshop, using SPSS, we compare two analyses of the same dataset: one using a t-test; another using LMMs. In the process, we introduce essential theoretical aspects of LMMs and highlight some of their advantages over traditional statistical methods.</p><h4 id="abs6" class="padtop32">Tourism Accessibility 4.0 - A Transition of e-Accessibility in Tourism Towards a More Inclusive Future</h4><p>Tourists are diverse consumers, including a large body of people with disabilities that all face physical, sensory, cognitive and cultural barriers in service provision and many tourism settings, including all travel phases. On the other hand, tourism as a technology-dependent industry relies heavily on information technology in service delivery that could further hamper the co-creation of tourist experiences for people with disabilities. However, all these barriers are situations that could be mitigated or even turned into possibilities with the recent advancement in Tourism 4.0 technologies, such as the Internet of Things (IoT), Big Data Analytics, Artificial Intelligence (AI), Blockchain, Location-based Services or Virtual and Augmented Reality Systems. Thus, this paper identifies gaps in the current e-accessibility practises in tourism industries that are usually narrow and task-oriented to identify new possibilities brought by Tourism 4.0 technologies that focus on interoperability, virtualization, decentralization, real-time data gathering and analysis capability, service orientation, and modularity. We discuss further research directions and questions for researchers that will allow the creation of more inclusive tourism that will be able to provide more meaningful and stimulating experiences accessible to all types of consumers.</p><h4 id="abs7" class="padtop32">Qualitative Research Methods in Media Accessibility: Focus Groups and Interviews</h4><p>Focus groups and interviews are two research methods often used to gather data in user-centric media accessibility research projects. Focus groups and interviews allow researchers to gather the subjective points of view of participants and are often used to complement quantitative data. This session will take a very practical approach: the main features of focus groups and interviews will be presented, and specific advice on how to plan, develop and analyse data gathered through these qualitative methods will be given. Examples from funded H2020 projects will be presented to illustrate how these methods have been used in media accessibility research.</p><h4 id="abs8" class="padtop32">Using Translation Process Methods in Audiovisual Translation and Media Accessibility Research</h4><p>Different AVT (e.g., subtitling, dubbing, voice-over) and MA (e.g. audio description, subtitling for the deaf and hard of hearing) modes may be defined both as product and process. While there is a growing body of research into AVT&amp;MA products, the process is still unexplored. Translation Process Research (TPR) essentially “seeks to answer one basic question: by what observable and presumed mental processes do translators arrive at their translations?” (Jakobsen, 2017, p. 21). To answer this question TPR uses a wide range of research methods which draw from psychology, corpus linguistics, psycholinguistics, anthropology, neuroscience, and writing research. In this session we will present the different methods (e.g. think aloud protocol, screen recording, keylogging, heart rate variability) used in TPR research and discuss how they can be applied to AVT&amp;MA.</p><h4 id="abs12" class="padtop32">Reading and writing eye-tracking research papers</h4><p>Eye-tracking research involves solid methodological preparation and thorough literature review. Before designing your own study, you should look at the way eye-tracking experiments are conducted and reported. You should also make sure you understand the gist of a given paper and are able to find the necessary information by looking in the right places. Apart from comprehension, you should also learn how to convert your ideas into a proper research proposal. Methodological preparation, theoretical underpinnings, hypotheses and expected results should be well-thought and written down before conducting your study.</p><p>During this workshop, we will look at the structure of research papers reporting eye-tracking experiments and identify the main points. We will focus on the analysis of the abstract, method and results, and on using this knowledge to plan and report a future study.</p><h4 id="abs13" class="padtop32">Introduction to Eye-Tracking and Biometric Experiments: Equipment Setup, Recording, and Analysis</h4><p>Research applications that involve eye-tracking require at the most basic level both determining where a subject is looking and what they are looking at. The application specific analysis can take place after these two steps. This talk will cover the best practices for the setup of eye-tracking equipment including equipment positioning, external environmental factors, participant variability, eye feature tracking, and calibration. Once a point-of-gaze is determined, the gaze position will be linked to the content viewed including static (text, images) and dynamic (videos, software) screen content, web content and mobile device screens. Finally, techniques for the initial processing of eye-tracking data will be covered including fixation maps, heatmaps, AOI’s and raw data export. Along with the focus on eye-tracking, the complementary biometric signals such as pupil size, heart rate and galvanic skin response will be discussed.</p></div></main><footer><div class="sociallinks"><div class="sociallinksContainer"><div class="costLogo"><img src="/images/cost.png" width="200" alt="cost"></div><div class="socialMediaLogos"><a href="https://twitter.com/COST_CA19142"><img src="/images/twitter.png" width="60" alt="Follow us on twitter"> </a><a href="https://www.youtube.com/channel/UCUMyxP5x9VcT11RMTWNaocA?view_as=subscriber"><img src="/images/youtube_logo.png" width="60" alt="Follow us on youtube"> </a><a href="https://www.linkedin.com/company/leadme-ca19142/"><img src="/images/linkedin_logo.png" width="60" alt="Follow us on linkedin"></a></div></div></div><div class="eulinks"><div class="eulinksContainer"><div class="euLogo"><img src="/images/eu-flag.jpg" width="90" alt="eu"><p>Funded by the Horizon 2020 Framework Programme of the European Union</p></div><div class="linkList"><a href="/accessibility/">LEAD-ME Accessibility Statement</a> <a href="https://www.w3.org/WAI/WCAG2AA-Conformance" title="Explanation of WCAG 2 Level AA conformance"><img height="32" width="88" src="https://www.w3.org/WAI/WCAG21/wcag2.1AA-v" alt="Level AA conformance, W3C WAI Web Content Accessibility Guidelines 2.1"></a></div></div></div></footer><script type="module" src="/js/main.js"></script><script type="text/javascript">var menubar = new Menubar(document.getElementById('mainNavMenu'));
  menubar.init();
  var menubutton = new Menubutton(document.getElementById('menubutton'));
  menubutton.init();</script></body></html>